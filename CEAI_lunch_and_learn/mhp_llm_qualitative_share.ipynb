{"cells":[{"cell_type":"markdown","source":["# Linguistic markers of subtle discrimination among mental healthcare professionals: CEAI Lunch-and-Learn"],"metadata":{"id":"pG6vcc1FQyh2"}},{"cell_type":"markdown","source":["_Performs qualitative deductive coding consistent with the  [CHALET](https://arxiv.org/abs/2405.05758) (**C**ollaborative **H**uman-LLM **A**na**L**ysis for **E**mpowering Conceptualization in Quali**T**ative Research) approach. Requires Ollama and/or OpenAI API key._"],"metadata":{"id":"IV7B3DTqRCCb"}},{"cell_type":"markdown","source":["> mhp_llm_qualitative_share.ipynb<br>\n","> Simone J. Skeen (01-30-2025)"],"metadata":{"id":"p_xtxjHnRGgu"}},{"cell_type":"markdown","source":["1. [Prepare](#scrollTo=TMzbQWcLnD3k)\n","2. [Write](#scrollTo=ro3vWHGknw3w)<br>\n","[_code_texts_deductively_llama_](#scrollTo=0TXsMF50oDSi)<br>\n","[_code_instance_deductively_gpt_](#scrollTo=LrgYlrmo1OUW)<br>\n","[_code_texts_deductively_gpt_](#scrollTo=I6V00vzh2Na1)<br>\n","3. [Code](#scrollTo=zXYJT6i9pSPf)<br>\n","[Llama 3.2: local](#scrollTo=6hHjuQXrAqLE)<br>\n","[GPT-4o: OpenAI API](#scrollTo=G1v8sP42Ah-n)<br>\n","4. [Fidelity](#scrollTo=6upq1MSmxvoW)<br>\n","[Compute Cohen's $\\kappa$](#scrollTo=DuSQ858FR2Ab)<br>\n","[Flag disagreements](#scrollTo=mC58zS16Zttc)\n"],"metadata":{"id":"Ot75cPlMRakI"}},{"cell_type":"markdown","metadata":{"id":"TMzbQWcLnD3k"},"source":["### Prepare\n","Installs, imports, requisite packages; customizes outputs.\n","***"]},{"cell_type":"markdown","metadata":{"id":"t6Rq0_Hj0lIb"},"source":["**Install**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0_sFYCXmuGE","tags":[]},"outputs":[],"source":["%%capture\n","\n","%pip install irrCAC\n","%pip install lime\n","%pip install ollama\n","%pip install openai"]},{"cell_type":"markdown","metadata":{"id":"s1SoN_HI0lId"},"source":["**Import**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8zJyDOUnTOa","tags":[]},"outputs":[],"source":["import json\n","import numpy as np\n","import ollama\n","import openai\n","import os\n","import pandas as pd\n","import re\n","import requests\n","import time\n","import warnings\n","\n","from google.colab import drive\n","from irrCAC.raw import CAC\n","from sklearn.metrics import cohen_kappa_score\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = 'all'\n","\n","pd.options.mode.copy_on_write = True\n","\n","pd.set_option(\n","    'display.max_columns',\n","    None,\n","    )\n","\n","pd.set_option(\n","    'display.max_rows',\n","    None,\n","    )\n","\n","warnings.simplefilter(\n","    action = 'ignore',\n","    category = FutureWarning,\n","    )\n","\n","#from langchain_community.llms import Ollama"]},{"cell_type":"markdown","metadata":{"id":"zKXbAwfN0lIf"},"source":["**Set env variables**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euvcHEZgq5mS","collapsed":true},"outputs":[],"source":["os.environ['OPENAI_API_KEY'] = ' '\n","os.environ"]},{"cell_type":"markdown","metadata":{"id":"30-J7Rqx0lIh"},"source":["**Directory structure**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8MCGclr0lIh"},"outputs":[],"source":["mhp_subtle_discrimination/\n","└── CEAI_lunch_and_learn/\n","    ├── code\n","    ├── inputs\n","    ├── outputs\n","    └── temp"]},{"cell_type":"markdown","metadata":{"id":"zBxmzqVQ0lIi"},"source":["**Ollama**<br>\n","http://localhost:11434/"]},{"cell_type":"markdown","metadata":{"id":"z-EvjhQp0lIi"},"source":["#### Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMvnCLepq5vY"},"outputs":[],"source":["# mount gdrive\n","\n","drive.mount(\n","    '/content/drive',\n","#    force_remount = True,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQMuvvNqrpGm"},"outputs":[],"source":["# structure directories\n","\n","%cd /content/drive/My Drive/Colab/mhp_subtle_discrimination"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6hq7NxXsG9a"},"outputs":[],"source":["#%mkdir CEAI_lunch_and_learn\n","#%cd CEAI_lunch_and_learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E762GqgXv9zn"},"outputs":[],"source":["#%mkdir inputs outputs code temp"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"FvW_mxkE0lIk"},"source":["#### JupyterLab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzFPrjAS0lIk"},"outputs":[],"source":["# set wd\n","\n","wd = ' '\n","os.chdir(wd)\n","%pwd"]},{"cell_type":"markdown","metadata":{"id":"ro3vWHGknw3w"},"source":["### Write\n","Defines qualitative.py module.\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqd3EKQVvaZd"},"outputs":[],"source":["%cd CEAI_lunch_and_learn/code"]},{"cell_type":"markdown","metadata":{"id":"0TXsMF50oDSi"},"source":["#### _code_texts_deductively_llama_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6i-GDuKEjCB6"},"outputs":[],"source":["%%writefile qualitative.py\n","\n","import requests\n","import json\n","import pandas as pd\n","\n","def code_texts_deductively_llama(df, alias, text_column, endpoint_url, prompt_template, model_name):\n","    \"\"\"\n","    Classifies each row of 'text' column in provided df in accord with human-specified prompt,\n","    includes chain-of-thought reasoning, returning explanations for classification decision.\n","\n","    Parameters:\n","    -----------\n","    df : pandas.DataFrame\n","        The DataFrame containing the text to classify.\n","    alias : str\n","        The alias (for brevity) of the qualitative code to be applied.\n","    text_column : str\n","        The column name in df containing the text to be analyzed.\n","    endpoint_url : str\n","        The URL where locally hosted Llama model runs.\n","    prompt_template : str\n","        The prompt text with a placeholder (e.g., '{text}') where the row's text will be inserted.\n","    model_name : str\n","        The model tasked with qualitative deductive coding.\n","\n","    Returns:\n","    --------\n","    pandas.DataFrame\n","        The original DataFrame with two new columns: '{alias}_llm' (either \"0\" or \"1\")\n","        and '{alias}_expl' (the explanation).\n","    \"\"\"\n","\n","    # dynamically create {alias} column names\n","\n","    label_column = f'{alias}_llm'\n","    explanation_column = f'{alias}_expl'\n","\n","    # create empty tag ['*_llm'] and reasoning ['*_expl'] column\n","\n","    df[label_column] = None\n","    df[explanation_column] = None\n","\n","    for idx, row in df.iterrows():\n","        row_text = row[text_column]\n","\n","        # replace '{text}' in prompt_template with df 'text' data\n","\n","        prompt = prompt_template.format(text = row_text)\n","\n","        # send request to local Llama endpoint.\n","\n","        response = requests.post(\n","            endpoint_url,\n","            headers = {'Content-Type': 'application/json'},\n","            json = {\n","                'model': model_name,\n","                'prompt': prompt,\n","                'stream': False\n","                },\n","        )\n","\n","        # print statements for debugging\n","\n","        print(response.status_code)\n","        print(response.text)\n","\n","        if response.status_code == 200:\n","            try:\n","                # parse top-level JSON\n","\n","                result_json = response.json()\n","\n","                # 'response' field contains JSON string\n","\n","                raw_response_str = result_json.get('response', ' ')\n","\n","                # extract only the JSON portion: identify first `{` and last `}` braces\n","\n","                start_idx = raw_response_str.find(\"{\")\n","                end_idx = raw_response_str.rfind(\"}\") + 1\n","\n","                if start_idx != -1 and end_idx != -1:\n","\n","                # extract and parse JSON portion\n","\n","                    valid_json_str = raw_response_str[start_idx:end_idx]\n","                    parsed_output = json.loads(valid_json_str)\n","\n","                # extract tag and reasoning fields\n","\n","                    label = parsed_output.get(label_column)\n","                    explanation = parsed_output.get(explanation_column)\n","                else:\n","                    print(\"No valid JSON found in response.\")\n","                    label = None\n","                    explanation = None\n","\n","            except (json.JSONDecodeError, KeyError, TypeError) as e:\n","                print(\"Parsing error:\", e)\n","                label = None\n","                explanation = None\n","\n","        else:\n","            label = None\n","            explanation = None\n","\n","        # insert classification results into df\n","\n","        df.at[idx, label_column] = label\n","        df.at[idx, explanation_column] = explanation\n","\n","    return df"]},{"cell_type":"markdown","source":["#### _code_instance_deductively_gpt_"],"metadata":{"id":"LrgYlrmo1OUW"}},{"cell_type":"code","source":["%%writefile -a qualitative.py\n","\n","import time\n","import openai\n","\n","api_key = ' '\n","client = openai.OpenAI(api_key = api_key)\n","\n","def code_instance_deductively_gpt(text, prompts):\n","    \"\"\"\n","    Applies annotation decisions, based on multiple prompts, to a given text; provides rationale and explanation.\n","    Parameters:\n","    - text: The text to annotate.\n","    - prompts: A list of prompts to apply to the text.\n","\n","    Returns:\n","    - result: The combined result from all prompts.\n","    \"\"\"\n","    try:\n","\n","        # concatenate prompts\n","\n","        prompt_content = ' '.join(prompts)\n","\n","        response = client.chat.completions.create(\n","            model = 'gpt-4o',\n","            temperature = 0.2,\n","            messages = [\n","                {\n","                    'role': 'system',\n","                    'content': prompt_content\n","                },\n","                {\n","                    'role': 'user',\n","                    'content': text\n","                }\n","            ]\n","        )\n","\n","        # collect results\n","\n","        result = ' '\n","        for choice in response.choices:\n","            result += choice.message.content\n","\n","        print(f'{text}: {result}')\n","        return result\n","    except Exception as e:\n","        print(f'Exception: {e}')\n","        return 'error'"],"metadata":{"id":"qRH3oevj1NqS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### _code_texts_deductively_gpt_"],"metadata":{"id":"I6V00vzh2Na1"}},{"cell_type":"code","source":["%%writefile -a qualitative.py\n","\n","def code_texts_deductively_gpt(df, prompts_per_code):\n","    \"\"\"\n","    Applies code_instance_deductively_gpt for multiple codes to each row in dataframe 'df'.\n","\n","    Parameters:\n","    - df: The dataframe containing texts to annotate.\n","    - prompts_per_code: A dictionary with tag names as keys and a list of prompts as values.\n","\n","    Returns:\n","    - df: The updated dataframe with annotation results.\n","    \"\"\"\n","    for index, row in df.iterrows():\n","        for tag, prompts in prompts_per_code.items():\n","            result = code_instance_deductively_gpt(row['text'], prompts)\n","            if result == 'error':\n","                continue\n","\n","            # initialize variables for annotation outputs\n","\n","            rationale, explanation = None, None\n","\n","            if f'{tag}_1' in result:\n","                tag_value = 1\n","\n","                # extract rationale\n","\n","                rationale = result.split(f'{tag}_rationale:')[1].split(f'{tag}_explanation:')[0].strip() if f'{tag}_rationale:' in result else None\n","\n","                # extract explanation\n","\n","                explanation = result.split(f'{tag}_explanation:')[1].strip() if f'{tag}_explanation:' in result else None\n","\n","            else:\n","                tag_value = 0\n","\n","            # results to df\n","\n","            df.at[index, f'{tag}_gpt'] = tag_value\n","            df.at[index, f'{tag}_rtnl_gpt'] = rationale\n","            df.at[index, f'{tag}_expl_gpt'] = explanation\n","\n","            # impose delay between API calls\n","\n","            time.sleep(1)\n","\n","    return df"],"metadata":{"id":"ZM-BoptZ-uwf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJvBy9EZy6yC"},"source":["#### Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxxb-t8Mne3_"},"outputs":[],"source":["from qualitative import(\n","    code_texts_deductively_llama,\n","    code_instance_deductively_gpt,\n","    code_texts_deductively_gpt,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MQLVYNIpRKg"},"outputs":[],"source":["%cd ../inputs\n","\n","d = pd.read_excel(\n","    'd_cycle_3_sjs.xlsx', ### d_cycle_3_sjs - IAA comparison w/ GPT-4o\n","    index_col = [0],\n","    )\n","\n","# replace ' ' w/ NaN\n","\n","d[[\n","    'agnt',\n","    'afrm',\n","    'brdn',\n","    'fitt',\n","    'just',\n","    'prbl',\n","    'rbnd',\n","    'refl',\n","    ]] = d[[\n","        'agnt',\n","        'afrm',\n","        'brdn',\n","        'fitt',\n","        'just',\n","        'prbl',\n","        'rbnd',\n","        'refl',\n","        ]].replace(\n","            r'^\\s*$',\n","            np.nan,\n","            regex = True,\n","            )\n","\n","# replace NaN w/ 0\n","\n","d[[\n","    'agnt',\n","    'afrm',\n","    'brdn',\n","    'fitt',\n","    'just',\n","    'prbl',\n","    'rbnd',\n","    'refl',\n","    ]] = d[[\n","        'agnt',\n","        'afrm',\n","        'brdn',\n","        'fitt',\n","        'just',\n","        'prbl',\n","        'rbnd',\n","        'refl',\n","        ]].apply(\n","            pd.to_numeric,\n","            downcast = 'integer',\n","            )\n","\n","d.fillna(\n","    0,\n","    inplace = True,\n","    )\n","\n","# texts: delete '<|PII|>' pseudoword\n","\n","texts = [\n","    'text',\n","         ]\n","\n","pseudoword_tokens = [\n","    #'<SPL>',\n","    '<|PII|>', ### 1/10: remove from 'rtnl' prior to training\n","    ]\n","\n","for t in texts:\n","    d[t] = d[t].replace(\n","        pseudoword_tokens,\n","        ' ',\n","        regex = True,\n","        )\n","\n","# rationales: replace NaN w/ '.'\n","\n","rationales = [\n","    'rtnl',\n","    #'afrm_llm_rtnl',\n","    #'agnt_llm_rtnl',\n","    #'fitt_llm_rtnl',\n","    #'just_llm_rtnl',\n","    #'refl_llm_rtnl',\n","    'note',\n","              ]\n","\n","for r in rationales:\n","    d[r] = d[r].astype(str)\n","    d[r] = d[r].str.replace(\n","        r'0',\n","        '.',\n","        regex = True,\n","        )\n","\n","# inspect\n","\n","d.info()\n","d.head(3)"]},{"cell_type":"markdown","metadata":{"id":"zXYJT6i9pSPf"},"source":["### Code\n","Enables human-LLM deductive coding: human-specified per-tag prompts, JSON-.xlsx structured outputs.\n","***"]},{"cell_type":"markdown","source":["#### Llama 3.2: local"],"metadata":{"id":"6hHjuQXrAqLE"}},{"cell_type":"markdown","source":["**Reflect (alias: `refl`): prompt formulation**"],"metadata":{"id":"8MptoNX7InKc"}},{"cell_type":"code","source":["role = '''\n","You are tasked with applying pre-defined qualitative codes to emails by mental health professionals (MHPs)\n","such as counselors, psychologists, and clinical social workers, replying to prospective clients.\n","\n","You will be provided a definition, instructions, and key exemplars of text to guide your coding decisions.\n","'''\n","\n","definition = '''\n","Definition of \"Reflect\": MHPs reflecting specific symptoms or concerns.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Reflect,\" output refl_llm as \"1\".\n","- Otherwise, output refl_llm as \"0\".\n","- Also provide a short explanation in exactly two sentences, stored in refl_expl.\n","\n","Please respond in valid JSON with keys \"refl_llm\" and \"refl_expl\" only.\n","\n","Text:\n","{text}\n","'''\n","\n","clarification = '''\n","- \"Reflect\" is limited to reflections of prospective clients’ symptoms (anxiety, depression, stress)\n","or clear synonyms thereof (“sadness”).\n","- \"Reflect\" does not apply to reflections of clients' identities.\n","'''\n","\n","    ### 1/10: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Reflect\"\n","\n","- \"It's clear your anxiety is disrupting your life. Let's do what we can to begin your healing journey.\"\n","\n","- \"Depression can be a bear. So sorry to hear of your struggles.\"\n","\n","- \"We've seen a lot of stress like yours going around lately, but it can be dealt with <|PII|>.\"\n","'''"],"metadata":{"id":"Z-ZgYvz7AhGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Code deductively**"],"metadata":{"id":"Jr7p63SDJLam"}},{"cell_type":"code","source":["%%capture\n","\n","# concatenate prompt as f-string\n","\n","refl_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","#print(refl_prompt)\n","\n","# locally hosted Llama endpoint\n","\n","llama_endpoint = 'http://localhost:11434/api/generate'\n","\n","# classify texts and update df\n","\n","d = code_texts_deductively_llama(\n","    d,\n","    alias = 'refl',\n","    text_column = 'text',\n","    endpoint_url = llama_endpoint,\n","    prompt_template = refl_prompt,\n","    model_name = 'llama3',\n",")\n"],"metadata":{"id":"OLNNLfpZI5Tw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### GPT-4o: OpenAI API"],"metadata":{"id":"G1v8sP42Ah-n"}},{"cell_type":"markdown","source":["**Role assignment**"],"metadata":{"id":"Mz52ct374QHO"}},{"cell_type":"code","source":["role = '''\n","You are tasked with applying pre-defined qualitative codes to emails by mental health professionals (MHPs)\n","such as counselors, psychologists, and clinical social workers, replying to prospective clients.\n","\n","You will be provided a definition, instructions, and key exemplars of text to guide your coding decisions.\n","'''"],"metadata":{"id":"29Y0eN5w4PCc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Affirm (alias: `afrm`): prompt formulation"],"metadata":{"id":"QNG5CskHg5XZ"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Affirm\": Responding in a manner that explicitly reinforces prospective client’s decision to seek therapy.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Affirm,\" respond with \"afrm_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"afrm_1\" or a \"0\" response.\n","- If your response is \"afrm_1,\" then begin a new paragraph with \"afrm\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"afrm_1\" or a \"0\" begin a new paragraph with \"afrm_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- Affirmation of treatment-seeking must be explicit\n","- Acknowledgements of the difficulty in seeking care fulfill the definition of \"Affirm\"\n","- Expressions of gratitude alone (\"thank you for reaching out\") do _not_ fulfill the definition of \"Affirm\"\n","- Ambiguous positive responses do _not_ fulfill the definition of \"Affirm\"\n","'''\n","    ### 1/20: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Affirm\"\n","\n","\"It takes bravery to ask for help, and I'm glad you made the choice <|PII|>.\"\n","\n","\"How amazing to take this first step, it can be tough decision to make, but I believe it is often the right one.\n","'''\n","\n","# concatenate prompt as f-string\n","\n","afrm_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(afrm_prompt)"],"metadata":{"collapsed":true,"id":"_6nFLSQ_g4n5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Agent (alias: `agnt`): prompt formulation"],"metadata":{"id":"C-uE_dtiwrLj"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Agent\": Interfacing with a prospective client via an automatic message or non-MHP staffer such as a scheduler or office coordinator.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Agent,\" respond with \"agnt_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"agnt_1\" or a \"0\" response.\n","- If your response is \"agnt_1,\" then begin a new paragraph with \"agnt\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"agnt_1\" or a \"0\" begin a new paragraph with \"agnt_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- Responses in which a clinician responds first, even to hand off to a scheduler, do _not_ fulfill the definition of \"Agent.\"\n","'''\n","    ### 1/20: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Agent\"\n","\n","\"Thank for choosing <|PII|> Counelling Center. We are eager to assist you. First, please reply to this message with your insurance details.\"\n","\n","\"We received your message regarding starting therapy with Dr. <|PII|>. She does currently have availability. We will need the folloing information.\"\n","'''\n","\n","# concatenate prompt as f-string\n","\n","agnt_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(agnt_prompt)"],"metadata":{"id":"59_9-lkQwqIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["dmnd"],"metadata":{"id":"SSiZE1bRw3I7"}},{"cell_type":"code","source":["# tk"],"metadata":{"id":"NFNC322JwvmE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Fit (alias: `fitt`): prompt formulation"],"metadata":{"id":"xC1TvrLew6yt"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Fit\": Explicitly mentioning the importance of client-MHP rapport, and/or alliance in a client-empowering manner.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Fit,\" respond with \"fitt_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"fitt_1\" or a \"0\" response.\n","- If your response is \"fitt_1,\" then begin a new paragraph with \"fitt\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"fitt_1\" or a \"0\" begin a new paragraph with \"fitt_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- Characteristic terms may include \"fit,\" \"match,\" \"compatibility.\"\n","'''\n","    ### 1/20: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Fit\"\n","\n","\"I prefer to schedule a gratis 30-minute call to be sure we'll be a good fit for each other.\"\n","\n","\"In the initial session, we can discuss our compatability in working toward your therapy goals.\"\n","\n","\"Let's first set aside an introductory session to explore your needs and assess our fit.\"\n","'''\n","\n","# concatenate prompt as f-string\n","\n","fitt_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(fitt_prompt)"],"metadata":{"id":"IdejIIqhw56r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Friction (alias: `frtn`): prompt formulation"],"metadata":{"id":"3artTCRiIwTl"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Friction\": MHPs interjecting and describing administrative burden as reality of provisioning social services\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Friction,\" respond with \"frtn_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"frtn_1\" or a \"0\" response.\n","- If your response is \"frtn_1,\" then begin a new paragraph with \"frtn\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"frtn_1\" or a \"0\" begin a new paragraph with \"frtn_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- Any response in which an MHP requires >2 additional steps from a client before therapy can begin fulfills the \"Friction\" definition\n","'''\n","    ### 1/20: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Friction\"\n","\n","\"Thank you for contacting<|PII|> Services. Before we can arrange an appointment, please take a moment to create an account on our\n","scheduling portal, enter your address and telephone information, and provide valid insurance, including uploading a photo of\n","your insurance card.\"\n","\n","'''\n","\n","# concatenate prompt as f-string\n","\n","frtn_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(frtn_prompt)"],"metadata":{"id":"ehz9L1gFIuFE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Justify (alias: `just`): prompt formulation"],"metadata":{"id":"P2zc_eC7w_9L"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Justify\": Providing a logistical reason for being unable to meet with prospective clientas a personal/professional courtesy.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Justify,\" respond with \"just_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"just_1\" or a \"0\" response.\n","- If your response is \"just_1,\" then begin a new paragraph with \"just\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"just_1\" or a '0', begin a new paragraph with \"just_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- Reasons may include full caseload, geographic bounds of licensure, imminent retirement.\n","- Rejections based on client identity do _not_ fulfill the definition of \"Justify.\"\n","'''\n","\n","    ### 1/10: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Justify\"\n","\n","\"I would love to be able to help, but my caseload is currently full and I cannot take new clients.\"\n","\n","\"Unfortunately I am fully booked through the next few months, and unable to commit to new appointments.\"\n","\n","'''\n","\n","# concatenate prompt as f-string\n","\n","just_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(just_prompt)"],"metadata":{"id":"kQenqQbaw_Qw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Rebound (alias: `rbnd`): prompt formulation"],"metadata":{"id":"v915-yTUxCUy"}},{"cell_type":"code","source":["definition = '''\n","Definition of \"Rebound\": Multiple burdensome queries imposed on the prospective client in response to appointment-seeking inquiries\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Rebound,\" respond with \"rbnd_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"rbnd_1\" or a \"0\" response.\n","- If your response is \"rbnd_1,\" then begin a new paragraph with \"rbnd\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"rbnd_1\" or a '0', begin a new paragraph with \"rbnd_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- More than 2 consecutive questions directed at a client fulfill the definition of \"Rebound.\"\n","\n","- Consecutive questions may be embedded within a single sentence\n","'''\n","\n","    ### 1/10: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Rebound\"\n","\n","\"First, does your insurance reimburse formental health and if so whichinsuranceis it?\"\n","\n","\"Are you able to meet in person? Will you require special accomdoations? When did your symptoms begin, and what event kicked them off?\"\n","\n","'''\n","\n","# concatenate prompt as f-string\n","\n","rbnd_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(rbnd_prompt)"],"metadata":{"id":"FDG9ppWzxBzL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Reflect (alias: `refl`): prompt formulation"],"metadata":{"id":"haZLX5ZdK1gP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pqK_srgpRSl"},"outputs":[],"source":["definition = '''\n","Definition of \"Reflect\": MHPs describing their ability to aid specific symptoms or concerns raised by the client.\n","'''\n","\n","instruction = '''\n","You will be provided with a piece of text. For each piece of text:\n","- If it meets the definition of \"Reflect,\" respond with \"refl_1\"\n","- Otherwise, respond with \"0\".\n","- You must choose a \"refl_1\" or a \"0\" response.\n","- If your response is \"refl_1,\" then begin a new paragraph with \"refl\"_rationale:\" and excerpt the sentences or\n","phrases that determined your decision. You are allowed to choose multiple sentences or phrases, divided by an\n","\"<|SPL|>\" token.\n","- Then, whether you have selected a \"refl_1\" or a '0', begin a new paragraph with \"refl_explanation:\" and provide\n","a two sentence explanation for your response.\n","'''\n","\n","clarification = '''\n","- \"Reflect\" is limited to reflections of prospective clients’ symptoms (anxiety, depression, stress)\n","or clear synonyms thereof (\"sadness\").\n","- \"Reflect\" does not apply to reflections of clients' identities.\n","'''\n","\n","    ### 1/10: examples below all human-created sham; updates tktk\n","\n","examples = '''\n","Below are human-validated examples of \"Reflect\"\n","\n","- \"It's clear your anxiety is disrupting your life. Let's do what we can to begin your healing journey.\"\n","\n","- \"Depression can be a bear. So sorry to hear of your struggles.\"\n","\n","- \"We've seen a lot of stress like yours going around lately, but it can be dealt with <|PII|>.\"\n","'''\n","\n","# concatenate prompt as f-string\n","\n","refl_prompt = f'{role}{definition}{instruction}{clarification}{examples}'\n","print(refl_prompt)"]},{"cell_type":"markdown","source":["**Code deductively**"],"metadata":{"id":"yIjbO2-m5T6i"}},{"cell_type":"code","source":["#%%capture\n","\n","# define prompts per code\n","\n","prompts_per_code = {\n","  'afrm': [afrm_prompt],\n","  'agnt': [agnt_prompt],\n","  'fitt': [fitt_prompt],\n","  #'frtn': [frtn_prompt],\n","  'just': [just_prompt],\n","  'rbnd': [rbnd_prompt],\n","  'refl': [refl_prompt],\n","  }\n","\n","# annotate df\n","\n","d = code_texts_deductively_gpt(\n","  d,\n","  prompts_per_code,\n","  )"],"metadata":{"id":"vWfWk4EH5TPa","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKFrQ9vU0lIo"},"outputs":[],"source":["# inspect\n","\n","#print(d)\n","d.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOfDGl5yp4AH"},"outputs":[],"source":["# export\n","\n","#%cd ../outputs\n","\n","#d.to_excel('d_cycle_3_sjs_gpt.xlsx')"]},{"cell_type":"markdown","source":["### 4. Fidelity\n","Calculates inter-coder reliability scores over indepednent coding applications, dummy codes disagreements for deliberation.\n","***"],"metadata":{"id":"6upq1MSmxvoW"}},{"cell_type":"markdown","source":["#### Compute Cohen's $\\kappa$"],"metadata":{"id":"DuSQ858FR2Ab"}},{"cell_type":"code","source":["%cd ../outputs\n","\n","#d = pd.read_excel(\n","#    'd_cycle_3_sjs_gpt.xlsx',\n","#    index_col = [0],\n","#    )\n","\n","#print(d.columns)\n","\n","# drop NaN\n","\n","d = d.dropna(subset = [\n","    'afrm_gpt',\n","    'agnt_gpt',\n","    'fitt_gpt',\n","    #'frtn_gpt',\n","    'just_gpt',\n","    'rbnd_gpt',\n","    'refl_gpt',\n","    ]\n","             )\n","\n","# inspect\n","\n","d.info()\n","d.head(3)"],"metadata":{"id":"9bMn_VFvT88s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define kappa fx\n","\n","def calculate_kappa(d, col1, col2):\n","    return cohen_kappa_score(d[col1], d[col2])\n","\n","col_pairs = [\n","    ('afrm', 'afrm_gpt'),\n","    ('agnt', 'agnt_gpt'),\n","    ('fitt', 'fitt_gpt'),\n","    #('brdn', 'frtn_gpt'),\n","    ('just', 'just_gpt'),\n","    ('rbnd', 'rbnd_gpt'),\n","    ('refl', 'refl_gpt'),\n","    ]\n","\n","# initialize dict\n","\n","kappa_results = {}\n","\n","# % agreement loop\n","\n","def calculate_percent_agreement(df, col_pairs):\n","    results = {}\n","    for col1, col2 in col_pairs:\n","        agreement = df[col1] == df[col2]\n","        percent_agreement = (agreement.sum() / len(df)) * 100\n","        results[f\"{col1} & {col2}\"] = percent_agreement\n","    return results\n","\n","percent_agreement_results = calculate_percent_agreement(d, col_pairs)\n","\n","for pair, percent in percent_agreement_results.items():\n","    print(f\"Percent agreement for {pair}: {percent:.2f}%\")\n","\n","# kappa loop\n","\n","for col1, col2 in col_pairs:\n","    kappa = calculate_kappa(d, col1, col2)\n","    kappa_results[f'{col1} and {col2}'] = kappa\n","\n","for pair, kappa in kappa_results.items():\n","    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n"],"metadata":{"id":"zt2p47yQRyrb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Flag disagreements"],"metadata":{"id":"mC58zS16Zttc"}},{"cell_type":"code","source":["# flag disagreements fx\n","\n","def encode_disagreements(row):\n","    return 1 if row[0] != row[1] else 0\n","\n","col_dis = [\n","    ('afrm', 'afrm_gpt', 'afrm_dis'),\n","    ('agnt', 'agnt_gpt', 'agnt_dis'),\n","    ('fitt', 'fitt_gpt', 'fitt_dis'),\n","    ('frtn', 'frtn_gpt', 'frtn_dis'),\n","    ('just', 'just_gpt', 'just_dis'),\n","    ('rbnd', 'rbnd_gpt', 'rbnd_dis'),\n","    ('refl', 'refl_gpt', 'refl_dis'),\n","  ]\n","\n","for col1, col2, dis_col in col_dis:\n","    d[dis_col] = d[[col1, col2]].apply(\n","        encode_disagreements,\n","        axis = 1,\n","        )\n","\n","# export\n","\n","d.to_excel(f'd_pilot_coded_iaa.xlsx')"],"metadata":{"id":"1U3ee6SkRyzL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"egPe72USqUis"},"source":["> End of mhp_llm_qualitative_share.ipynb"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["3artTCRiIwTl"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}