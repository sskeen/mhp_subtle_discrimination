{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a2d5145-7d61-44b3-b692-45b10ce45ad2",
      "metadata": {
        "id": "2a2d5145-7d61-44b3-b692-45b10ce45ad2"
      },
      "source": [
        "## Linguistic markers of subtle discrimination among mental healthcare professionals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118c708c-2753-4071-bb5c-837ab25d0780",
      "metadata": {
        "id": "118c708c-2753-4071-bb5c-837ab25d0780"
      },
      "source": [
        "_Preprocesses, trains, tests (5-fold CV), and ranks feature importance of mental health professional (MHP) response quality targets while replying to appointment queries, using binary XGBoost classifiers. Fine tunes and evaluates (5-fold CV) rationale-augmented MHP response quality targets across BERT, RoBERTa, and DistilBERT pretrained LMs._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3dd7d28-46f5-4c73-a4a9-4b4613295ec7",
      "metadata": {
        "id": "a3dd7d28-46f5-4c73-a4a9-4b4613295ec7"
      },
      "source": [
        "> mhp_train_test_pilot.ipynb<br>\n",
        "> Simone J. Skeen (06-28-2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation\n",
        "Installs and imports packages, mounts gdrive, calibrates output preferences."
      ],
      "metadata": {
        "id": "T-EsFbk8khl3"
      },
      "id": "T-EsFbk8khl3"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install bertopic\n",
        "%pip install causalnlp\n",
        "%pip install contractions\n",
        "%pip install simpletransformers\n",
        "%pip install unidecode\n",
        "%pip install wandb\n",
        "\n",
        "!python -m spacy download en_core_web_lg --user"
      ],
      "metadata": {
        "id": "e2DaWUbFLnhl",
        "collapsed": true
      },
      "id": "e2DaWUbFLnhl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "import logging\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import re\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "#import stata_setup\n",
        "import string\n",
        "import wandb.sdk\n",
        "import warnings\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from bs4 import BeautifulSoup\n",
        "from causalnlp import CausalInferenceModel\n",
        "from causalnlp.key_driver_analysis import KeyDriverAnalysis\n",
        "from causalnlp.autocoder import Autocoder\n",
        "from collections import Counter\n",
        "from functools import reduce\n",
        "from google.colab import drive\n",
        "from hdbscan import HDBSCAN\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, average_precision_score, matthews_corrcoef\n",
        "from textblob import TextBlob\n",
        "from umap import UMAP\n",
        "from unidecode import unidecode\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "pd.set_option(\n",
        "              'display.max_columns',\n",
        "              None,\n",
        "              )\n",
        "\n",
        "pd.set_option(\n",
        "              'display.max_rows',\n",
        "              None,\n",
        "              )\n",
        "\n",
        "warnings.simplefilter(\n",
        "                      action = 'ignore',\n",
        "                      category = FutureWarning,\n",
        "                      )\n",
        "\n",
        "#!python -m prodigy stats"
      ],
      "metadata": {
        "id": "Tq8uXi_4LxT2"
      },
      "id": "Tq8uXi_4LxT2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\n",
        "            '/content/gdrive/',\n",
        "            force_remount = True,\n",
        "            )\n",
        "\n",
        "%cd gdrive/My Drive/Colab/mhp_subtle_discrimination/data"
      ],
      "metadata": {
        "id": "yoa5ilNUOivV"
      },
      "id": "yoa5ilNUOivV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-annotation\n",
        "Imports raw parent study data, reduces, annonymizes, for annotation tasks.\n",
        "***"
      ],
      "metadata": {
        "id": "EJRze3oKGX3q"
      },
      "id": "EJRze3oKGX3q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Import_**"
      ],
      "metadata": {
        "id": "vS9NDYhKGXtA"
      },
      "id": "vS9NDYhKGXtA"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "d = pd.read_csv(\n",
        "                'Therapy Discrimination - Data collection file - Response Data.csv',\n",
        "                encoding = 'utf8',\n",
        "                header = 1,\n",
        "                )\n",
        "\n",
        "print(len(d.columns))\n",
        "for col in d.columns:\n",
        "    print(col)\n",
        "d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HtqMs7FuM3AS"
      },
      "id": "HtqMs7FuM3AS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Reformat_**"
      ],
      "metadata": {
        "id": "ew3yQx-CTmGG"
      },
      "id": "ew3yQx-CTmGG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce\n",
        "\n",
        "d = d[[\n",
        "       'Response (Y/N)',\n",
        "       'Email Pair ID#',\n",
        "       'Within Patient ID',\n",
        "       'First Email in Pair? (Y/N)',\n",
        "       'Email, Phone, or Text (E/P/T)',\n",
        "       'Offered a pre-appt consultation/to talk on the phone? (Y/N)',\n",
        "       'Implied or explicit appointment offer? (Y/N)',\n",
        "       'Rejection? (Y/N)',\n",
        "       'Asked about insurance/payment? (Y/N)',\n",
        "       'Asked about trans/nonbinary issues? (Y/N)',\n",
        "       'Copy-and-Paste Email Response of Voicemail (if called but no voicemail, leave empty)',\n",
        "       'Outcome Recode (A = Appointment, C = Call offer, Q = Screening questions, W = Waitlist, R = Referral, X = Rejection, NV = no voice message, N = No response, I = Inconclusive)\\n',\n",
        "       'Secondary Outcome Recode (A = Appointment, C = Call offer, Q = Screening questions, W = Waitlist, R = Referral, X = Rejection, NV = no voice message, N = No response, I = Inconclusive)',\n",
        "       ]]\n",
        "\n",
        "# Rename\n",
        "\n",
        "d.rename(\n",
        "         columns = {\n",
        "                    'Response (Y/N)': 'response',\n",
        "                    'Email Pair ID#': 'email_pair_id',\n",
        "                    'Within Patient ID': 'client_id',\n",
        "                    'First Email in Pair? (Y/N)': 'first_email',\n",
        "                    'Email, Phone, or Text (E/P/T)': 'ept',\n",
        "                    'Offered a pre-appt consultation/to talk on the phone? (Y/N)': 'consult',\n",
        "                    'Implied or explicit appointment offer? (Y/N)': 'appointment',\n",
        "                    'Rejection? (Y/N)': 'reject',\n",
        "                    'Asked about insurance/payment? (Y/N)' : 'tnb_ask',\n",
        "                    'Asked about trans/nonbinary issues? (Y/N)' : 'ins_ask',\n",
        "                    'Copy-and-Paste Email Response of Voicemail (if called but no voicemail, leave empty)': 'text',\n",
        "                    'Outcome Recode (A = Appointment, C = Call offer, Q = Screening questions, W = Waitlist, R = Referral, X = Rejection, NV = no voice message, N = No response, I = Inconclusive)\\n': 'prmr_outcome',\n",
        "                    'Secondary Outcome Recode (A = Appointment, C = Call offer, Q = Screening questions, W = Waitlist, R = Referral, X = Rejection, NV = no voice message, N = No response, I = Inconclusive)': 'scnd_outcome',\n",
        "                    }, inplace = True,\n",
        "        )\n",
        "\n",
        "# Restrict: response = 1\n",
        "\n",
        "d = d[d['response'] == 1.0]\n",
        "\n",
        "# Encode 'Y/N' string\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "outcomes = [\n",
        "            'first_email',\n",
        "            'consult',\n",
        "            'appointment',\n",
        "            'reject',\n",
        "            'tnb_ask',\n",
        "            'ins_ask',\n",
        "            ]\n",
        "\n",
        "for outcome in outcomes:\n",
        "    if d[outcome].isnull().any():\n",
        "        d[outcome].fillna(\n",
        "                          'unknown',\n",
        "                          inplace = True,\n",
        "                          )\n",
        "\n",
        "    d[outcome] = le.fit_transform(d[outcome])\n",
        "    d[outcome].replace({\n",
        "                        2: 1,\n",
        "                        1: 0,\n",
        "                            }, inplace = True,\n",
        "                       )\n",
        "\n",
        "# Reindex\n",
        "\n",
        "d = d.reset_index()\n",
        "d = d.drop(\n",
        "           'index',\n",
        "           axis = 1,\n",
        "           )\n",
        "\n",
        "d.index.name = 'index'\n",
        "\n",
        "d.shape\n",
        "d.dtypes\n",
        "d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dDD1ZJkYOCLz"
      },
      "id": "dDD1ZJkYOCLz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Anonymize_**"
      ],
      "metadata": {
        "id": "5DteHCVCTy6R"
      },
      "id": "5DteHCVCTy6R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define spaCy NE redaction Fx\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def redact_ne(mhp_text):\n",
        "    '''replaces named entities with <|PII|>'''\n",
        "    ne = list(\n",
        "              [\n",
        "               'PERSON',   ### people, including fictional\n",
        "               'NORP',     ### nationalities or religious or political groups\n",
        "               'FAC',      ### buildings, airports, highways, bridges, etc.\n",
        "               'ORG',      ### companies, agencies, institutions, etc.\n",
        "               'GPE',      ### countries, cities, states\n",
        "               'LOC',      ### non-GPE locations, mountain ranges, bodies of water\n",
        "               'PRODUCT',  ### objects, vehicles, foods, etc. (not services)\n",
        "               'EVENT',    ### named hurricanes, battles, wars, sports events, etc.\n",
        "               ]\n",
        "                )\n",
        "\n",
        "    doc = nlp(mhp_text)\n",
        "    ne_to_remove = []\n",
        "    final_string = str(mhp_text)\n",
        "    for sent in doc.ents:\n",
        "        if sent.label_ in ne:\n",
        "            ne_to_remove.append(str(sent.text))\n",
        "    for n in range(len(ne_to_remove)):\n",
        "        final_string = final_string.replace(\n",
        "                                            ne_to_remove[n],\n",
        "                                            '<|PII|>',\n",
        "                                            )\n",
        "    return final_string"
      ],
      "metadata": {
        "id": "msb3MF3QVgHc"
      },
      "id": "msb3MF3QVgHc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NER redaction\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact_ne(i))\n",
        "\n",
        "# Excise numerals\n",
        "\n",
        "d['text'] = d['text'].apply(lambda i: re.sub(\n",
        "                                             r'\\d+',\n",
        "                                             ' ',\n",
        "                                             i,\n",
        "                                             )\n",
        "                            )\n",
        "\n",
        "# Harmonize manual redactions\n",
        "\n",
        "redactions = [\n",
        "              '[PATIENT NAME]',\n",
        "              '[MHP NAME]',\n",
        "              '[CITY]',\n",
        "              ]\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: reduce(\n",
        "                                                         lambda s, r: s.replace(\n",
        "                                                                                r,\n",
        "                                                                                '<|PII|>',\n",
        "                                                                                ), redactions, i\n",
        "                                                         )\n",
        "                                        )\n",
        "\n",
        "\n",
        "#                           )\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: i.replace(\n",
        "                                                            '\\n',\n",
        "                                                            ' ',\n",
        "                                                            )\n",
        "                                        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4bm0k0VWTxs3"
      },
      "id": "4bm0k0VWTxs3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Export for annotation_**"
      ],
      "metadata": {
        "id": "hKXJJqnAyZDH"
      },
      "id": "hKXJJqnAyZDH"
    },
    {
      "cell_type": "code",
      "source": [
        "d.to_excel('d_anon.xlsx')"
      ],
      "metadata": {
        "id": "tAXWiX2NUV3T"
      },
      "id": "tAXWiX2NUV3T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-annotation\n",
        "Cleans, formats, and augments _n_ = 755 annotated pilot dataset.\n",
        "***"
      ],
      "metadata": {
        "id": "56RZyYisUXlt"
      },
      "id": "56RZyYisUXlt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Import_**"
      ],
      "metadata": {
        "id": "3FeligZV1TXE"
      },
      "id": "3FeligZV1TXE"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "d = pd.read_excel(\n",
        "                  'd_annotated_pilot.xlsx',\n",
        "                  index_col = 0,\n",
        "                  )\n",
        "\n",
        "d.shape\n",
        "d.dtypes\n",
        "d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2ecedEAVy-49"
      },
      "id": "2ecedEAVy-49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Replace NaN_**"
      ],
      "metadata": {
        "id": "26hg27-Bh_9L"
      },
      "id": "26hg27-Bh_9L"
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [\n",
        "           'prob', ### prob = exploratory-qualitative only\n",
        "           'refl',\n",
        "           'just',\n",
        "           'afrm',\n",
        "           'fit',\n",
        "           'agnt',\n",
        "           ]\n",
        "\n",
        "for target in targets:\n",
        "    d[target].fillna(\n",
        "                     0,\n",
        "                     inplace = True,\n",
        "                     )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zz6PwMbDy-x8"
      },
      "id": "Zz6PwMbDy-x8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Encode intra-textual treatment_**"
      ],
      "metadata": {
        "id": "JhYYMVOZ2CFG"
      },
      "id": "JhYYMVOZ2CFG"
    },
    {
      "cell_type": "code",
      "source": [
        "ac = Autocoder()\n",
        "\n",
        "texts = d['text'].astype(str).tolist()\n",
        "\n",
        "d = ac.code_custom_topics(\n",
        "                          texts,\n",
        "                          d,\n",
        "                          labels = [\n",
        "                                    'transgender',\n",
        "                                    'insurance',\n",
        "                                    ])\n",
        "\n",
        "# Binarize\n",
        "\n",
        "d['t_bin'] = d['transgender'].apply(lambda i: 1 if i > 0.5 else 0)\n",
        "d['i_bin'] = d['insurance'].apply(lambda i: 1 if i > 0.5 else 0)\n",
        "\n",
        "d[[\n",
        "   'refl',\n",
        "   'just',\n",
        "   'afrm',\n",
        "   'fit',\n",
        "   'agnt',\n",
        "   't_bin',\n",
        "   'i_bin',\n",
        "    ]].apply(pd.Series.value_counts)\n",
        "\n",
        "d.head(30)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y8BrZ50V2BcT"
      },
      "id": "y8BrZ50V2BcT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export condensed, non-augmented, dataset for cluster\n",
        "\n",
        "d_analysis_pilot = d[[\n",
        "                      'text',\n",
        "                      'prob',\n",
        "                      'refl',\n",
        "                      'just',\n",
        "                      'afrm',\n",
        "                      'fit',\n",
        "                      'agnt',\n",
        "                      't_bin',\n",
        "                      'i_bin',\n",
        "                      'rationale',\n",
        "                      ]].copy()\n",
        "\n",
        "d_analysis_pilot.to_excel('d_analysis_pilot.xlsx')"
      ],
      "metadata": {
        "id": "jbEBvZwBiEeY"
      },
      "id": "jbEBvZwBiEeY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Augment_**"
      ],
      "metadata": {
        "id": "yiz4-X_MJ2lO"
      },
      "id": "yiz4-X_MJ2lO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode 'target'\n",
        "\n",
        "d['target'] = d[[\n",
        "                 'refl',\n",
        "                 'just',\n",
        "                 'afrm',\n",
        "                 'fit',\n",
        "                 'agnt',\n",
        "                 ]].apply(\n",
        "                          lambda row: 1 if any(row) else 0,\n",
        "                          axis = 1,\n",
        "                          )\n",
        "\n",
        "#d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "txGZog4iEZk0"
      },
      "id": "txGZog4iEZk0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(df):\n",
        "    '''Identifies all pos(1) target rows, duplicates as new row, replaces new row text cell with rationale'''\n",
        "    new_rows = []\n",
        "    for index, row in df.iterrows():\n",
        "        if row['target'] > 0:\n",
        "            new_row = row.copy()  # Create a copy for the new row\n",
        "            new_row['text'] = row['rationale']  # Modify 'text' in the NEW row\n",
        "            new_rows.append((index + 0.5, new_row))  # Use fractional index for insertion\n",
        "\n",
        "    # Insert new rows and sort by index\n",
        "    for index, new_row in new_rows:\n",
        "        df = pd.concat([df.iloc[:int(index)],\n",
        "                        pd.DataFrame([new_row], index=[index]),\n",
        "                        df.iloc[int(index):]])\n",
        "    df = df.sort_index().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "d = augment(d.copy())  # Create a copy to avoid modifying the original DataFrame\n",
        "\n",
        "d.shape\n",
        "d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l1tmMXBBb9Vj"
      },
      "id": "l1tmMXBBb9Vj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed546565-e9d8-482a-86f0-39910c5cffd2",
      "metadata": {
        "id": "ed546565-e9d8-482a-86f0-39910c5cffd2"
      },
      "outputs": [],
      "source": [
        "# Drop annotation artifacts\n",
        "\n",
        "artifacts = [\n",
        "             '<PII>', ### <PII> _only_ in non-augmented data\n",
        "             '<PROB>',\n",
        "             '<JUST>',\n",
        "             '<AFRM>',\n",
        "             '<FIT>',\n",
        "             '<AGNT>',\n",
        "             '<REFL>',\n",
        "             '[PHONE NUMBER]',\n",
        "             ]\n",
        "\n",
        "for artifact in artifacts:\n",
        "    d['text'] = d['text'].str.replace(\n",
        "                                      artifact,\n",
        "                                      ' ',\n",
        "                                      regex = True,\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4fa89c-0e39-4086-8e24-4a491b3ca5ba",
      "metadata": {
        "id": "6e4fa89c-0e39-4086-8e24-4a491b3ca5ba"
      },
      "outputs": [],
      "source": [
        "d.to_excel('d_augmented_pilot.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Latent Class Analysis: PyStata\n",
        "Detects latent response-quality outcome, visualizes latent class distribution.\n",
        "***"
      ],
      "metadata": {
        "id": "Ir47_j442Yw9"
      },
      "id": "Ir47_j442Yw9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PyStata"
      ],
      "metadata": {
        "id": "NbiXNodfG7QX"
      },
      "id": "NbiXNodfG7QX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "\n",
        "#stata_setup.config('C:/Program Files/Stata18', 'se'"
      ],
      "metadata": {
        "id": "5RLAx0a6Hxud"
      },
      "id": "5RLAx0a6Hxud",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_mhp_latent_class_pilot.do_**"
      ],
      "metadata": {
        "id": "ONpL9T9DH_MR"
      },
      "id": "ONpL9T9DH_MR"
    },
    {
      "cell_type": "code",
      "source": [
        "\t\t### SJS 6/28: see mhp_latent_class_pilot.do"
      ],
      "metadata": {
        "id": "13u4ZHX3H2lP"
      },
      "id": "13u4ZHX3H2lP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Viz."
      ],
      "metadata": {
        "id": "VMe3kHvDIPX5"
      },
      "id": "VMe3kHvDIPX5"
    },
    {
      "cell_type": "code",
      "source": [
        "d_viz = pd.DataFrame(dict(\n",
        "                       value = [0.229704, 0.000001, 0.161597, 0.067374, 0.404319, ### cond mean\n",
        "                                0.000001, 0.072105, 0.042612, 0.058599, 0.000001],\n",
        "                      variable = ['Affirm', 'Agent', 'Fit', 'Justify', 'Reflect', ### manifest var\n",
        "                                  'Affirm', 'Agent', 'Fit', 'Justify', 'Reflect'],\n",
        "                      rq_class = ['Engaged (27%)', 'Engaged (27%)', 'Engaged (27%)', 'Engaged (27%)', 'Engaged (27%)',\n",
        "                                  'Detached (73%)', 'Detached (73%)', 'Detached (73%)', 'Detached (73%)', 'Detached (73%)']))\n",
        "\n",
        "fig = px.line_polar(\n",
        "                    d_viz,\n",
        "                    r = 'value',\n",
        "                    theta = 'variable',\n",
        "                    line_close = True,\n",
        "                    #color_discrete_sequence = px.colors.sequential.Plasma_r,\n",
        "\n",
        "                    color_discrete_sequence = [px.colors.qualitative.Alphabet[13],\n",
        "                                              px.colors.qualitative.Alphabet[0]],\n",
        "\n",
        "\n",
        "                    color = 'rq_class',\n",
        "                   )\n",
        "\n",
        "fig.update_layout(\n",
        "                  polar = dict(\n",
        "                               radialaxis = dict(\n",
        "                                                 visible = True,\n",
        "                                                 range=[0, 0.5],\n",
        "                                                 showticklabels = True,\n",
        "                                                 gridwidth = 0,\n",
        "                                                 #ticks = ' ',\n",
        "                                                ),\n",
        "                               angularaxis = dict(\n",
        "                                                  showticklabels = True,\n",
        "                                                  gridwidth = 0,\n",
        "                                                  #ticks = ' ',\n",
        "                                                  )\n",
        "                               ),\n",
        "                  showlegend = True,\n",
        "                  #title = 'xx',\n",
        "                  #titlefont = {\n",
        "                  #             'size': 28,\n",
        "                  #             'family':'Serif',\n",
        "                  #             },\n",
        "                  template = 'plotly_white',\n",
        "                  #paper_bgcolor = 'white',\n",
        "                  width = 900,\n",
        "                  height = 700,\n",
        "                  )\n",
        "\n",
        "fig.update_traces(\n",
        "                  fill = 'toself',\n",
        "                  opacity = 0.4,\n",
        "                  )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "zdxRPBKWRixM"
      },
      "id": "zdxRPBKWRixM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model A: XGBoost\n",
        "***"
      ],
      "metadata": {
        "id": "QsbT_xdSeG9r"
      },
      "id": "QsbT_xdSeG9r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4e9fd7-1fa9-4873-9557-ef57f9286499",
      "metadata": {
        "tags": [],
        "id": "9f4e9fd7-1fa9-4873-9557-ef57f9286499"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "\n",
        "# Convert to lowercase\n",
        "\n",
        "t_col = d['text_response_anon'].astype(str).apply(lambda i: i.lower())\n",
        "\n",
        "# Expand contractions\n",
        "\n",
        "t_col = t_col.apply(lambda i: ' '.join([contractions.fix(expanded_word) for expanded_word in i.split()]))\n",
        "\n",
        "# Excise numbers\n",
        "\n",
        "t_col = t_col.apply(lambda i: re.sub(r'\\d+', ' ', i))\n",
        "\n",
        "# Excise punctuation\n",
        "\n",
        "t_col = t_col.apply(lambda i: re.sub('[%s]' % re.escape(string.punctuation), ' ' , i))\n",
        "\n",
        "# Convert diacriticals\n",
        "\n",
        "t_col = t_col.apply(lambda i: unidecode(i, errors = 'preserve'))\n",
        "\n",
        "        ### _note_ 10/5: errors = 'preserve': retain if no replacement character possible\n",
        "\n",
        "# Standardize/correct spelling\n",
        "\n",
        "t_col = t_col.apply(lambda i: str(TextBlob(i).correct()))\n",
        "\n",
        "        ### SJS 3/19: ~5 min runtime...\n",
        "\n",
        "# Update stoplist\n",
        "\n",
        "sw_nltk = stopwords.words('english')\n",
        "sw_add = [\n",
        "          'um',\n",
        "          ]\n",
        "\n",
        "sw_nltk.extend(sw_add)\n",
        "\n",
        "# Apply updated stoplist\n",
        "\n",
        "d['text_response_pre'] = t_col.apply(lambda i: ' '.join([ word for word in i.split() if word not in sw_nltk]))\n",
        "\n",
        "# Inspect\n",
        "\n",
        "d.head(3)\n",
        "d.to_csv('d_inspect.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac694110-9d01-450f-b4ad-a37b37e09231",
      "metadata": {
        "tags": [],
        "id": "ac694110-9d01-450f-b4ad-a37b37e09231"
      },
      "outputs": [],
      "source": [
        "# Contextualize artifacts from pilot runs\n",
        "\n",
        "d_inspect = pd.read_csv(\n",
        "                        'd_inspect.csv',\n",
        "                        encoding = 'unicode_escape',\n",
        "                        header = 0,\n",
        "                        )\n",
        "\n",
        "\n",
        "# Unstandardized text: 'um'\n",
        "\n",
        "d_inspect['text_response_pre'] = d_inspect['text_response_pre'].apply(lambda i: nltk.word_tokenize(str(i)) if i is not None else [])\n",
        "nltk_t = nltk.Text(word for tokens in d['text_response_pre'] for word in tokens)\n",
        "\n",
        "print(nltk_t.concordance('um', width = 120, lines = 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccdac3ba-1c67-4793-8694-133443847171",
      "metadata": {
        "tags": [],
        "id": "ccdac3ba-1c67-4793-8694-133443847171"
      },
      "outputs": [],
      "source": [
        "# Count vectorize\n",
        "\n",
        "        ### _note_ 3/7: accomodating feature importance downstream...\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#cv = CountVectorizer(\n",
        "#                     ngram_range = (1, 3),\n",
        "#                     min_df = 0.01, ### ignore tokens that appear in <1% of responses\n",
        "                     #stop_words = 'english',\n",
        "#                     )\n",
        "\n",
        "#cv_matrix = cv.fit_transform(d['text_response_pre'].values.astype('U'))\n",
        "\n",
        "#cv_d = pd.DataFrame(cv_matrix.toarray(), columns = cv.get_feature_names_out())\n",
        "#cv_d.shape\n",
        "\n",
        "#cv_features = pd.concat([d, cv_d], axis = 1) ### f = features\n",
        "\n",
        "#cv_features.head(3)\n",
        "\n",
        "        ### _note_ 3/7: export, c/b of use\n",
        "\n",
        "#cv_features.to_csv('mh_document-feature_matrix.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f147248c-3ac4-4a24-9777-0788f4db7b7a",
      "metadata": {
        "id": "f147248c-3ac4-4a24-9777-0788f4db7b7a"
      },
      "outputs": [],
      "source": [
        "#tfidf vectorize\n",
        "\n",
        "tv = TfidfVectorizer(\n",
        "                     ngram_range = (1, 3),\n",
        "                     min_df = 0.01, ### ignore tokens that appear in <1% of responses\n",
        "                     #stop_words = 'english',\n",
        "                     )\n",
        "\n",
        "tf_matrix = tv.fit_transform(d['text_response_pre'].values.astype('U'))\n",
        "\n",
        "tf_d = pd.DataFrame(tf_matrix.toarray(), columns = tv.get_feature_names_out())\n",
        "tf_d.shape\n",
        "\n",
        "\n",
        "tf_features = pd.concat([d, tf_d], axis = 1)\n",
        "\n",
        "tf_features.head(3)\n",
        "\n",
        "#tf_features.to_csv('mh_document-feature_matrix.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089c283c-8431-4433-86c9-1b139b8b1fe5",
      "metadata": {
        "id": "089c283c-8431-4433-86c9-1b139b8b1fe5"
      },
      "outputs": [],
      "source": [
        "# Value counts\n",
        "\n",
        "d[[\n",
        "   'refl',\n",
        "   'just',\n",
        "   'afrm',\n",
        "   'fit',\n",
        "   'agnt',\n",
        "   ]].apply(pd.Series.value_counts)\n",
        "\n",
        "        ### _note_ 3/26: computed for '_QUAL' (non-augmented) df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fb1ba8-68f5-4f63-b79b-62246a75288c",
      "metadata": {
        "tags": [],
        "id": "89fb1ba8-68f5-4f63-b79b-62246a75288c"
      },
      "outputs": [],
      "source": [
        "# Weights\n",
        "\n",
        "'refl: p_w'\n",
        "674 / 81 # p_w = 8.3210\n",
        "\n",
        "'just: p_w'\n",
        "709 / 46 # p_w = 15.4130\n",
        "\n",
        "'afrm: p_w'\n",
        "709 / 46 # p_w = 15.4130\n",
        "\n",
        "'fit: p_w'\n",
        "699 / 56 # p_w = 12.4821\n",
        "\n",
        "'agnt: p_w'\n",
        "715 / 40 # p_w = 17.8750\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d47692cb-e18e-4afc-85bf-4183039b2c06",
      "metadata": {
        "tags": [],
        "id": "d47692cb-e18e-4afc-85bf-4183039b2c06"
      },
      "outputs": [],
      "source": [
        "# Dummy code augmented rows\n",
        "\n",
        "d['augment'] = 0\n",
        "\n",
        "t_indices = d['rationale'].apply(lambda i: isinstance(i, str))\n",
        "\n",
        "d.loc[t_indices.shift(1, fill_value = False), 'augment'] = 1\n",
        "\n",
        "        ### _note_ 3/21: use for 'drop if' prior to eval to avoid inflated metrics - annotated data _only_\n",
        "\n",
        "d.head(10)\n",
        "#d.to_csv('d_inspect.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f555ef-61f0-4e36-baf7-1f39bf8dd00a",
      "metadata": {
        "tags": [],
        "id": "43f555ef-61f0-4e36-baf7-1f39bf8dd00a"
      },
      "source": [
        "**rskf train-test-feature loop: _not_ augmented**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1536afcb-c9c0-40e1-b47f-f448349baf6e",
      "metadata": {
        "tags": [],
        "id": "1536afcb-c9c0-40e1-b47f-f448349baf6e"
      },
      "outputs": [],
      "source": [
        "\n",
        "targets = [\n",
        "           'refl',\n",
        "           'just',\n",
        "           'afrm',\n",
        "           'fit',\n",
        "           'agnt',\n",
        "           ]\n",
        "\n",
        "# Scale pos weights: n neg / n pos\n",
        "\n",
        "p_w = {\n",
        "       'refl': 8.3210,\n",
        "       'just': 15.4130,\n",
        "       'afrm': 15.4130,\n",
        "       'fit':  12.4821,\n",
        "       'agnt': 17.8750,\n",
        "       }\n",
        "\n",
        "\n",
        "for target in targets:\n",
        "    '''Preprocesses, trains, tests (5-fold CV), and ranks feature importance of mental health professional (MHP)\n",
        "    response quality targets while replying to appointment queries, using binary XGBoost classifiers.'''\n",
        "\n",
        "    X = d['text_response_pre'].astype(str)\n",
        "    y = d[target]\n",
        "\n",
        "    # Vectorize\n",
        "\n",
        "    #cv = CountVectorizer(\n",
        "                         #binary = True,\n",
        "                         #ngram_range = (1, 3),\n",
        "                         #min_df = 0.01,\n",
        "                         #stop_words = 'english',\n",
        "                         #)\n",
        "\n",
        "    tv = TfidfVectorizer(\n",
        "                         ngram_range = (1, 3),\n",
        "                         min_df = 0.01,\n",
        "                         #stop_words = 'english',\n",
        "                         )\n",
        "\n",
        "    #X_count = cv.fit_transform(X)\n",
        "    X_tfidf = tv.fit_transform(X)\n",
        "\n",
        "    # Convert sparse matrix to dense array\n",
        "\n",
        "    #X_count = X_count.toarray()\n",
        "    X_tfidf = X_tfidf.toarray()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        #X_count,\n",
        "                                                        X_tfidf,\n",
        "                                                        y,\n",
        "                                                        test_size = 0.2,\n",
        "                                                        stratify = y,\n",
        "                                                        random_state = 56,\n",
        "                                                        )\n",
        "\n",
        "    # Scale\n",
        "\n",
        "    s = StandardScaler()\n",
        "\n",
        "        ### _note_ 3/7: _fit_ on training set only\n",
        "\n",
        "    X_train_scaled = s.fit_transform(X_train)\n",
        "    X_test_scaled = s.transform(X_test)\n",
        "\n",
        "    # Classifier params\n",
        "\n",
        "    xgb = XGBClassifier(\n",
        "                        scale_pos_weight = p_w[target],\n",
        "                        #verbosity = 0,\n",
        "                        )\n",
        "\n",
        "    # Cross validate\n",
        "\n",
        "    n_splits = 5\n",
        "    n_repeats = 5\n",
        "    rskf = RepeatedStratifiedKFold(\n",
        "                                   n_splits = n_splits,\n",
        "                                   n_repeats = n_repeats,\n",
        "                                   random_state = 56,\n",
        "                                   )\n",
        "\n",
        "    # Lists to store eval metrics\n",
        "\n",
        "    f1_macro = []\n",
        "    auprc = []\n",
        "    mcc = []\n",
        "\n",
        "    # Iterate over k-fold splits\n",
        "\n",
        "    for train_index, val_index in rskf.split(X_train_scaled, y_train):\n",
        "        X_train_cv, X_val_cv = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "        # Train\n",
        "\n",
        "        xgb.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "        # Predict on validation set\n",
        "\n",
        "        y_pred_val = xgb.predict(X_val_cv)\n",
        "\n",
        "        # F1 macro, AUPRC, MCC eval\n",
        "\n",
        "        f1_macro.append(f1_score(y_val_cv, y_pred_val, average = 'macro'))\n",
        "        auprc.append(average_precision_score(y_val_cv, xgb.predict_proba(X_val_cv)[:, 1], average = 'macro'))\n",
        "        mcc.append(matthews_corrcoef(y_val_cv, y_pred_val))\n",
        "\n",
        "    print('----------------------------------------------------------------------------------------')\n",
        "    print(f'\\nTarget: {target}')\n",
        "    print(f'Average F1 Macro: {sum(f1_macro) / len(f1_macro)}')\n",
        "    print(f'Average AUPRC: {sum(auprc) / len(auprc)}')\n",
        "    print(f'Average MCC: {sum(mcc) / len(mcc)}')\n",
        "\n",
        "    # Plot feature importances\n",
        "\n",
        "    #print('----------------------------------------------------------------------------------------')\n",
        "    #plt.figure(figsize = (20, 260))\n",
        "    #sorted_idx = xgb.feature_importances_.argsort()\n",
        "\n",
        "        ### SJS 3/7: _NOTE_'tf_d' assigned in cell above\n",
        "\n",
        "    #plt.barh(tf_d.columns[sorted_idx], xgb.feature_importances_[sorted_idx], color = 'skyblue')\n",
        "    #plt.xlabel(\"XGBoost Feature Importance\")\n",
        "\n",
        "    #plt.title(f'Feature Importance - {target}')\n",
        "    #plt.show()\n",
        "\n",
        "    # List feature importances\n",
        "\n",
        "    print('----------------------------------------------------------------------------------------')\n",
        "    feature_names = tv.get_feature_names()\n",
        "    importance_scores = xgb.feature_importances_\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance_scores})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by = 'Importance', ascending=False)\n",
        "\n",
        "    top_20_features = feature_importance_df.head(20)\n",
        "    print(f'\\nTop 20 features for {target}:')\n",
        "    print(top_20_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c256667-1759-46d5-9ea2-1911405bee28",
      "metadata": {
        "id": "5c256667-1759-46d5-9ea2-1911405bee28"
      },
      "source": [
        "### Model B: BERT(s)\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414d351e-53bc-4b27-bf0c-ba66243f978c",
      "metadata": {
        "id": "414d351e-53bc-4b27-bf0c-ba66243f978c"
      },
      "outputs": [],
      "source": [
        "os.chdir('<my_dir>')\n",
        "#%pwd\n",
        "\n",
        "# Import\n",
        "\n",
        "        ### _note_ 3/7: mh_audit_wave1_QUAL = single-annotated, n = 755\n",
        "\n",
        "        ### _note_ 3/21: mh_audit_wave1_QUAL_aug = single-annotated, _manually_ augmented w/ rationales, n = 990\n",
        "\n",
        "d = pd.read_csv(\n",
        "                'mh_audit_wave1_QUAL_aug.csv',\n",
        "                encoding = 'unicode_escape',\n",
        "                header = 0,\n",
        "                )\n",
        "\n",
        "# Replace NaN\n",
        "\n",
        "targets = [\n",
        "           'prob', ### prob = _not_ coherent target; expl only\n",
        "           'refl',\n",
        "           'just',\n",
        "           'afrm',\n",
        "           'fit',\n",
        "           'agnt',\n",
        "           ]\n",
        "\n",
        "for target in targets:\n",
        "    d[target].fillna(0, inplace = True)\n",
        "\n",
        "# Dummy code augmented rows\n",
        "\n",
        "d['augment'] = 0\n",
        "\n",
        "t_indices = d['rationale'].apply(lambda i: isinstance(i, str))\n",
        "\n",
        "d.loc[t_indices.shift(1, fill_value = False), 'augment'] = 1\n",
        "\n",
        "# Drop annotation artifacts\n",
        "\n",
        "artifacts = [\n",
        "             '<PII>',\n",
        "             '<PROB>',\n",
        "             '<JUST>',\n",
        "             '<AFRM>',\n",
        "             '<FIT>',\n",
        "             '<AGNT>',\n",
        "             '<REFL>',\n",
        "             ]\n",
        "\n",
        "for artifact in artifacts:\n",
        "    d['text_response_aug'] = d['text_response_aug'].str.replace(artifact, ' ', regex = True)\n",
        "\n",
        "d.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f5f4f2-9229-46f3-bac8-8d3520a85250",
      "metadata": {
        "id": "90f5f4f2-9229-46f3-bac8-8d3520a85250"
      },
      "outputs": [],
      "source": [
        "# SimpleTransformer prep\n",
        "\n",
        "#d.head(3)\n",
        "#d.columns\n",
        "d['text'] = d['text_response_aug'].str.replace(r'<PII>', ' ', regex = True)\n",
        "d.drop(\n",
        "       columns = [\n",
        "                  'id',\n",
        "                  'response',\n",
        "                  'emailpair',\n",
        "                  'pid',\n",
        "                  'firstemail',\n",
        "                  'ept',\n",
        "                  'consult',\n",
        "                  'appointment',\n",
        "                  'reject',\n",
        "                  'text_response_anon',\n",
        "                  'prob',\n",
        "                  'rationale',\n",
        "                  'notes',\n",
        "                  'prmr_outcome',\n",
        "                  'scnd_outcome',\n",
        "                  #'text_response_pre',\n",
        "                  ], inplace = True)\n",
        "\n",
        "st_format = [\n",
        "             'text',\n",
        "             'augment',\n",
        "             'refl',\n",
        "             'just',\n",
        "             'afrm',\n",
        "             'fit',\n",
        "             'agnt',\n",
        "             ]\n",
        "\n",
        "d = d[st_format]\n",
        "d.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5411749b-366f-4480-b30b-20b10d8578a6",
      "metadata": {
        "id": "5411749b-366f-4480-b30b-20b10d8578a6"
      },
      "outputs": [],
      "source": [
        "d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f8abaf-f170-4d8e-ac66-9515af5752a7",
      "metadata": {
        "tags": [],
        "id": "94f8abaf-f170-4d8e-ac66-9515af5752a7"
      },
      "outputs": [],
      "source": [
        "# Class weights: N / n classes * n\n",
        "\n",
        "c_w = {\n",
        "       'refl': {\n",
        "                '0': 0.5978,\n",
        "                '1': 3.0556,\n",
        "                },\n",
        "       'just': {\n",
        "                '0': 0.5525,\n",
        "                '1': 5.2660,\n",
        "                },\n",
        "       'afrm': {\n",
        "                '0': 0.5518,\n",
        "                '1': 5.3226,\n",
        "                },\n",
        "       'fit': {\n",
        "                '0': 0.5644,\n",
        "                '1': 4.3805,\n",
        "                },\n",
        "       'agnt': {\n",
        "                '0': 0.5464,\n",
        "                '1': 5.8929,\n",
        "                }\n",
        "       }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d6e85d",
      "metadata": {
        "scrolled": true,
        "id": "06d6e85d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# View defaults\n",
        "\n",
        "'BERT defaults'\n",
        "bert_uncased = ClassificationModel(\n",
        "                                   'bert',\n",
        "                                   'bert-large-uncased',\n",
        "                                   use_cuda = False,\n",
        "                                   )\n",
        "bert_uncased.args\n",
        "\n",
        "'RoBERTa defaults'\n",
        "roberta_base = ClassificationModel(\n",
        "                                    'roberta',\n",
        "                                    'roberta-base',\n",
        "                                    use_cuda = False,\n",
        "                                    )\n",
        "roberta_base.args\n",
        "\n",
        "'DistilBERT defaults'\n",
        "distilbert_base = ClassificationModel(\n",
        "                                      'distilbert',\n",
        "                                      'distilbert-base-cased',\n",
        "                                      use_cuda = False,\n",
        "                                      )\n",
        "distilbert_base.args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e148d253-f972-4fa3-bb85-79f7f4e23982",
      "metadata": {
        "id": "e148d253-f972-4fa3-bb85-79f7f4e23982"
      },
      "source": [
        "**kf train-test loop: _augmented_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c248690f-e293-43ec-b796-7518d0ec6110",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "c248690f-e293-43ec-b796-7518d0ec6110"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Fx iterates over models, args, subconstructs, class weights\n",
        "\n",
        "def train_and_evaluate_model(model_type, model_name, target, class_weights, train_d, eval_d):\n",
        "    '''Fine tunes and evaluates (5-fold CV) rationale-augmented MHP response quality targets across BERT, RoBERTa, and\n",
        "    DistilBERT pretrained LMs.'''\n",
        "\n",
        "    print('======================================================================================')\n",
        "    print(f\"\\nTraining {model_type}:{model_name}, target **{target}**\")\n",
        "    print('======================================================================================')\n",
        "\n",
        "    # Args\n",
        "\n",
        "    model_args = ClassificationArgs(\n",
        "                                    num_train_epochs = 2,\n",
        "                                    sliding_window = False, ### ~2x runtime w/ True; 'jagged arrays' incompatible w/ loop\n",
        "                                    #do_lower_case = True,\n",
        "                                    #reprocess_input_data = False,\n",
        "                                    overwrite_output_dir = True,\n",
        "                                    manual_seed = 56,\n",
        "                                    )\n",
        "\n",
        "    # Initialize model(s)\n",
        "\n",
        "    model = ClassificationModel(\n",
        "                                model_type = model_type,\n",
        "                                model_name = model_name,\n",
        "                                use_cuda = False,\n",
        "                                num_labels = 2,\n",
        "                                weight = class_weights[target],\n",
        "                                args = model_args,\n",
        "                                )\n",
        "\n",
        "    # Train\n",
        "\n",
        "    model.train_model(train_d)\n",
        "\n",
        "    print(f\"Evaluating {model_type} model for {target}\")\n",
        "\n",
        "    # Eval\n",
        "\n",
        "    result, model_outputs, _ = model.eval_model(eval_d)\n",
        "\n",
        "    # Metric\n",
        "\n",
        "    predictions = np.argmax(model_outputs, axis = 1)\n",
        "    f1_macro = f1_score(eval_d[target], predictions, average = 'macro')\n",
        "\n",
        "    print('----------------------------------------------------------------------------------------')\n",
        "    print(f\"F1 macro: {model_type} for {target} = {f1_macro}\")\n",
        "    print(\"Evaluation:\")\n",
        "    print(result)\n",
        "\n",
        "# Model types, model names\n",
        "\n",
        "model_types = [\n",
        "               'bert',\n",
        "               'roberta',\n",
        "               'distilbert',\n",
        "                ]\n",
        "\n",
        "model_names = [\n",
        "               'bert-base-cased',\n",
        "               'roberta-base',\n",
        "               'distilbert-base-cased',\n",
        "                ]\n",
        "\n",
        "# Class weights\n",
        "\n",
        "class_weights = {\n",
        "                 'refl': [\n",
        "                          0.5978,\n",
        "                          3.0556,\n",
        "                          ],\n",
        "                 'just': [\n",
        "                          0.5525,\n",
        "                          5.2660,\n",
        "                          ],\n",
        "                 'afrm': [\n",
        "                          0.5518,\n",
        "                          5.3226,\n",
        "                          ],\n",
        "                 'fit': [\n",
        "                         0.5644,\n",
        "                         4.3805,\n",
        "                         ],\n",
        "                 'agnt': [\n",
        "                          0.5464,\n",
        "                          5.8929,\n",
        "                          ]\n",
        "                 }\n",
        "\n",
        "# Iterate over models\n",
        "\n",
        "for model_type, model_name in zip(model_types, model_names):\n",
        "\n",
        "    # Iterate over subconstructs\n",
        "\n",
        "    for target in [\n",
        "                   'refl',\n",
        "                   'just',\n",
        "                   'afrm',\n",
        "                   'fit',\n",
        "                   'agnt',\n",
        "                   ]:\n",
        "\n",
        "        # Stratified train-test split\n",
        "\n",
        "#        train_df, eval_df = train_test_split(\n",
        "#                                             trans_df[['text', target]],\n",
        "#                                             test_size = 0.2,\n",
        "#                                             stratify = trans_df[target],\n",
        "#                                             random_state = 56,\n",
        "#                                             )\n",
        "\n",
        "        # Subconstruct-stratified 5-fold cv\n",
        "\n",
        "        d_subset = d[['text', target, 'augment']]\n",
        "\n",
        "        kf = KFold(\n",
        "                   n_splits = 5,\n",
        "                   shuffle = True,\n",
        "                   random_state = 56,\n",
        "                   )\n",
        "\n",
        "        for train_index, eval_index in kf.split(d_subset):\n",
        "            train_d, eval_d = d_subset.iloc[train_index], d_subset.iloc[eval_index]\n",
        "\n",
        "            eval_d = eval_d[eval_d['augment'] != 1]\n",
        "\n",
        "            train_and_evaluate_model(\n",
        "                                     model_type,\n",
        "                                     model_name,\n",
        "                                     target,\n",
        "                                     class_weights,\n",
        "                                     train_d,\n",
        "                                     eval_d,\n",
        "                                     )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd1a5fa-b84e-4b09-9fc7-2e89e4ea726c",
      "metadata": {
        "id": "3cd1a5fa-b84e-4b09-9fc7-2e89e4ea726c"
      },
      "source": [
        "> End of mh_audit_v1.ipynb (03-28-2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic Model: BERTopic"
      ],
      "metadata": {
        "id": "ZUv4D08iKwsA"
      },
      "id": "ZUv4D08iKwsA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Import_**"
      ],
      "metadata": {
        "id": "byIxPu5OLUv0"
      },
      "id": "byIxPu5OLUv0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5a95c2-e501-48ee-a307-568c6744cf64",
      "metadata": {
        "id": "2e5a95c2-e501-48ee-a307-568c6744cf64",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "d = pd.read_excel(\n",
        "                  'd_analysis_pilot.xlsx',\n",
        "                  index_col = 0,\n",
        "                  )\n",
        "\n",
        "d.shape\n",
        "d.dtypes\n",
        "d.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Preprocess_**"
      ],
      "metadata": {
        "id": "P-fmXK_NLbPG"
      },
      "id": "P-fmXK_NLbPG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ffjivAMcLqzH"
      },
      "outputs": [],
      "source": [
        "# Drop annotation artifacts\n",
        "\n",
        "artifacts = [\n",
        "             '<PII>',\n",
        "             '[PHONE NUMBER]',\n",
        "             ]\n",
        "\n",
        "for artifact in artifacts:\n",
        "    d['text'] = d['text'].str.replace(\n",
        "                                      artifact,\n",
        "                                      ' ',\n",
        "                                      regex = True,\n",
        "                                      )\n",
        "\n",
        "# Convert to lowercase\n",
        "\n",
        "t_col = d['text'].astype(str).apply(lambda i: i.lower())\n",
        "\n",
        "# Expand contractions\n",
        "\n",
        "t_col = t_col.apply(lambda i: ' '.join([contractions.fix(expanded_word) for expanded_word in i.split()]))\n",
        "\n",
        "# Excise numbers\n",
        "\n",
        "t_col = t_col.apply(lambda i: re.sub(r'\\d+', ' ', i))\n",
        "\n",
        "# Excise punctuation\n",
        "\n",
        "t_col = t_col.apply(lambda i: re.sub('[%s]' % re.escape(string.punctuation), ' ' , i))\n",
        "\n",
        "# Convert diacriticals\n",
        "\n",
        "t_col = t_col.apply(lambda i: unidecode(i, errors = 'preserve'))\n",
        "\n",
        "        ### _note_ 10/5: errors = 'preserve': retain if no replacement character possible\n",
        "\n",
        "# Standardize/correct spelling\n",
        "\n",
        "t_col = t_col.apply(lambda i: str(TextBlob(i).correct()))\n",
        "\n",
        "        ### SJS 3/19: ~5 min runtime...\n",
        "\n",
        "# Update stoplist\n",
        "\n",
        "sw_nltk = stopwords.words('english')\n",
        "sw_add = [\n",
        "          'um',\n",
        "          ]\n",
        "\n",
        "sw_nltk.extend(sw_add)\n",
        "\n",
        "# Apply updated stoplist\n",
        "\n",
        "d['text'] = t_col.apply(lambda i: ' '.join([ word for word in i.split() if word not in sw_nltk]))\n",
        "\n",
        "# Inspect\n",
        "\n",
        "d.head(3)\n",
        "d.to_excel('d_inspect.xlsx')"
      ],
      "id": "ffjivAMcLqzH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Baseline: model defaults_**"
      ],
      "metadata": {
        "id": "cP8gxUSCNsJb"
      },
      "id": "cP8gxUSCNsJb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hA1v3ZflmRn7"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Responses - convert to str\n",
        "\n",
        "texts = [str(responses) for responses in d.text]\n",
        "\n",
        "# Set random seed\n",
        "\n",
        "umap_model = UMAP(random_state = 56)\n",
        "\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# Tune clustering\n",
        "\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "\n",
        "\n",
        "\n",
        "# Prep embeddings\n",
        "\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = sentence_model.encode(\n",
        "                                   texts,\n",
        "                                   show_progress_bar = True,\n",
        "                                   )\n",
        "\n",
        "# Initialize\n",
        "\n",
        "topic_model = BERTopic(\n",
        "                       calculate_probabilities = True,\n",
        "                       #nr_topics = 100, ###\n",
        "                       #n_gram_range = (1, 3),\n",
        "                       #seed_topic_list = seed_topic_list,\n",
        "                       min_topic_size = 6,\n",
        "                       umap_model = umap_model,\n",
        "                       verbose = True,\n",
        "                       )\n",
        "\n",
        "topics, probs = topic_model.fit_transform(\n",
        "                                          texts,\n",
        "                                          embeddings,\n",
        "                                          )\n",
        "\n",
        "# Tabulate doc-level probabilities of topic inclusion\n",
        "\n",
        "d_prob = pd.DataFrame(\n",
        "                      probs,\n",
        "                      columns=[f\"topic_{i}\" for i in range(probs.shape[1])],\n",
        "                      )\n",
        "\n",
        "# Merge w/ d\n",
        "\n",
        "d_with_topics = pd.concat(\n",
        "                          [\n",
        "                           d,\n",
        "                           d_prob,\n",
        "                           ],\n",
        "                          axis = 1,\n",
        "                          )\n",
        "\n",
        "# Inspect\n",
        "\n",
        "#d_with_topics.head(30)\n",
        "d_with_topics.to_csv('d_with_topics.csv', index = True)"
      ],
      "id": "hA1v3ZflmRn7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Save_**"
      ],
      "metadata": {
        "id": "BhRWPo4FOiNt"
      },
      "id": "BhRWPo4FOiNt"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "topic_model.save(\n",
        "                 'mhp_topic_model_bl',\n",
        "                 serialization = 'safetensors',\n",
        "                 save_ctfidf = True,\n",
        "                 save_embedding_model = embedding_model,\n",
        "                 )"
      ],
      "metadata": {
        "id": "r9H3Pg7yOTkc"
      },
      "id": "r9H3Pg7yOTkc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Viz._**"
      ],
      "metadata": {
        "id": "8PfMY3zROroo"
      },
      "id": "8PfMY3zROroo"
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info().head(20).set_index('Topic')\n",
        "\n",
        "topic_model.visualize_barchart(\n",
        "                               width = 280,\n",
        "                               height = 330,\n",
        "                               top_n_topics = 8,\n",
        "                               n_words = 10,\n",
        "                               )"
      ],
      "metadata": {
        "id": "K9-GIf9QOn8c"
      },
      "id": "K9-GIf9QOn8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "y0jHlEl5O1pl"
      },
      "id": "y0jHlEl5O1pl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intra-Textual Causal Inference: CausalNLP\n",
        "***"
      ],
      "metadata": {
        "id": "X79A66TtNQwf"
      },
      "id": "X79A66TtNQwf"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "d = pd.read_excel(\n",
        "                  'd_causal_pilot.xlsx',\n",
        "                  index_col = 0,\n",
        "                  )\n",
        "\n",
        "d.shape\n",
        "d.dtypes\n",
        "d.head(3)"
      ],
      "metadata": {
        "id": "eFxHYOjKPjDh",
        "collapsed": true
      },
      "id": "eFxHYOjKPjDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = d.drop(columns = ['rationale'])"
      ],
      "metadata": {
        "id": "-9-xQlw0Vh89"
      },
      "id": "-9-xQlw0Vh89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CausalInferenceModel(\n",
        "                          d,\n",
        "                          method = 't-learner',\n",
        "                          treatment_col = 't_bin',\n",
        "                          outcome_col = 'engaged_cl',\n",
        "                          include_cols = [\n",
        "                          #               'index',\n",
        "                          #               'text',\n",
        "                          #               'prbl',\n",
        "                          #               'refl',\n",
        "                          #               'just',\n",
        "                          #               'afrm',\n",
        "                          #               'fitt',\n",
        "                          #               'agnt',\n",
        "                                         'i_bin',\n",
        "                                         #'rationale',\n",
        "                          #               '_est_one_class',\n",
        "                          #               '_est_two_class',\n",
        "                          #               '_est_three_class',\n",
        "                          #               '_est_rq_class2_t',\n",
        "                          #               '_est_rq_class2',\n",
        "                          #               'cpr1',\n",
        "                          #               'cpr2',\n",
        "                          #               'maxpr',\n",
        "                                          ]\n",
        "                          )\n",
        "cm.fit()"
      ],
      "metadata": {
        "id": "LTFJyv64PVN4"
      },
      "id": "LTFJyv64PVN4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ate = cm.estimate_ate()\n",
        "ate"
      ],
      "metadata": {
        "id": "0Xp5mtutVC_L"
      },
      "id": "0Xp5mtutVC_L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> End of mhp_train_test_pilot.ipynb"
      ],
      "metadata": {
        "id": "l_bsSvjcer5R"
      },
      "id": "l_bsSvjcer5R"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "56RZyYisUXlt",
        "NbiXNodfG7QX",
        "VMe3kHvDIPX5",
        "QsbT_xdSeG9r",
        "5c256667-1759-46d5-9ea2-1911405bee28",
        "ZUv4D08iKwsA"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}